{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecção de Argumentos Faltantes em Artigos da Wikipedia com Gemini API\n",
    "\n",
    "Este notebook demonstra como usar a API Gemini (via `google-generativeai`) para analisar seções de um artigo da Wikipedia e identificar argumentos ou contra-argumentos importantes que podem estar faltando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports, Configuração da API e Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Gemini configurada com sucesso.\n"
     ]
    }
   ],
   "source": [
    "# Imports principais\n",
    "import os\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if api_key:\n",
    "    try:\n",
    "        genai.configure(api_key=api_key)\n",
    "        print(\"API Gemini configurada com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao configurar a API Gemini: {e}\")\n",
    "        api_key = None # Garante que não tentaremos usar uma configuração falha\n",
    "\n",
    "# Constantes do Modelo\n",
    "DEFAULT_MODEL_NAME = \"gemini-1.5-flash-latest\"\n",
    "DEFAULT_TEMPERATURE = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Função Auxiliar para Parse da Resposta JSON do LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_llm_json_response(response_text: str) -> list[dict] | dict:\n",
    "    \"\"\"\n",
    "    Tenta analisar a string de resposta JSON do LLM.\n",
    "    Remove possíveis blocos de código Markdown e, se a análise direta falhar,\n",
    "    tenta um fallback analisando linha por linha objetos JSON.\n",
    "    Retorna uma lista de dicionários, um dicionário, ou uma lista vazia em caso de falha.\n",
    "    \"\"\"\n",
    "    if not response_text:\n",
    "        return []\n",
    "\n",
    "    cleaned_text = response_text.strip()\n",
    "    \n",
    "    # Remove ```json ... ``` ou ``` ... ``` se presentes\n",
    "    if cleaned_text.startswith(\"```json\"):\n",
    "        cleaned_text = cleaned_text[7:]\n",
    "        if cleaned_text.endswith(\"```\"):\n",
    "            cleaned_text = cleaned_text[:-3]\n",
    "    elif cleaned_text.startswith(\"```\") and cleaned_text.endswith(\"```\"):\n",
    "        cleaned_text = cleaned_text[3:-3]\n",
    "            \n",
    "    cleaned_text = cleaned_text.strip()\n",
    "\n",
    "    try:\n",
    "        # Tenta carregar o JSON diretamente\n",
    "        return json.loads(cleaned_text)\n",
    "    \n",
    "    except json.JSONDecodeError:\n",
    "        # print(f\"DEBUG: JSONDecodeError na resposta completa. Tentando fallback linha por linha. Resposta:\\n{cleaned_text}\") # Para debug\n",
    "        items = []\n",
    "        for line in cleaned_text.splitlines():\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"{\") and line.endswith(\"}\"):\n",
    "                try:\n",
    "                    # Remove vírgulas no final de uma linha, se houver (comum em listas JSON mal formatadas)\n",
    "                    if line.endswith(\",\"):\n",
    "                        line = line[:-1]\n",
    "                    items.append(json.loads(line))\n",
    "                except json.JSONDecodeError:\n",
    "                    # print(f\"DEBUG: Não foi possível decodificar a linha JSON: {line}\") # Para debug\n",
    "                    pass # Ignora linhas que não são JSON válidos\n",
    "            elif line == \"[\" or line == \"]\": # Ignora colchetes de lista em linhas separadas\n",
    "                pass\n",
    "        \n",
    "        # Se 'items' contém apenas um dicionário, e o JSON original não parecia ser uma lista, retorna o dicionário.\n",
    "        if len(items) == 1 and not (cleaned_text.startswith(\"[\") and cleaned_text.endswith(\"]\")):\n",
    "            if cleaned_text.startswith(\"{\") and cleaned_text.endswith(\"}\"):\n",
    "                return items[0]\n",
    "        \n",
    "        if not items and cleaned_text == \"[]\": \n",
    "            return []\n",
    "        # print(f\"DEBUG: Itens extraídos pelo fallback: {items}\") # Para debug\n",
    "        return items if items else [] # Retorna a lista de itens ou uma lista vazia se nada foi parseado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Função para Obter Argumentos Faltantes de UMA Seção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_args_for_section(section_title: str, section_text: str, article_summary: str | None = None, max_args: int = 2, model_name: str = DEFAULT_MODEL_NAME) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Analisa um trecho de uma seção de artigo da Wikipedia e identifica argumentos faltantes.\n",
    "    Retorna uma lista de dicionários, cada um com 'argument' e 'priority'.\n",
    "    \"\"\"\n",
    "    context_summary = \"\"\n",
    "    if article_summary:\n",
    "        context_summary = article_summary.strip()\n",
    "        if len(context_summary) > 600:\n",
    "            context_summary = context_summary[:597] + \"...\"           \n",
    "        \n",
    "    prompt = f\"\"\"\n",
    "You are an assistant specialized in critical content analysis.\n",
    "Analyze the following excerpt from a Wikipedia article section and identify up to {max_args} arguments, counter-arguments,\n",
    "or important viewpoints that appear to be missing or could enrich the discussion about the section's topic.\n",
    "\n",
    "For each missing item identified, provide:\n",
    "- \"argument\": A clear and concise description of the missing argument/point and how it matters for the text understand.\n",
    "- \"priority\": An integer from 1 (most important/impactful) to {max_args} (least important among those identified).\n",
    "\n",
    "Return your response as a pure JSON list of objects.\n",
    "If no relevant arguments or points are missing, return an empty JSON list: `[]`.\n",
    "\n",
    "Section Title (for context): \"{section_title}\"\n",
    "Section Excerpt:\n",
    "\\\"\\\"\\\"{section_text.strip()}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        model_client = genai.GenerativeModel(model_name)\n",
    "        generation_config = genai.types.GenerationConfig(temperature=DEFAULT_TEMPERATURE, max_output_tokens=256)  \n",
    "            \n",
    "        response = model_client.generate_content(prompt, generation_config=generation_config)\n",
    "        \n",
    "        response_content = \"\"\n",
    "        if response and hasattr(response, 'text') and response.text:\n",
    "            response_content = response.text\n",
    "        elif response and response.parts: # Modelos mais novos podem usar 'parts'\n",
    "             response_content = \"\".join([part.text for part in response.parts if hasattr(part, 'text')])\n",
    "\n",
    "        if response_content:\n",
    "            parsed_response = _parse_llm_json_response(response_content)\n",
    "            if isinstance(parsed_response, list):\n",
    "                return parsed_response\n",
    "            elif isinstance(parsed_response, dict) and parsed_response: # Se retornou um dict único, envolve em lista\n",
    "                return [parsed_response]\n",
    "            else:\n",
    "                return []\n",
    "        else:\n",
    "            # print(f\"WARN: Resposta inesperada, vazia ou sem texto processável do modelo para seção '{section_title}'.\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao chamar a API Gemini para a seção '{section_title}': {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Função para Coletar Argumentos Faltantes de Todas as Seções de um Artigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_args_for_article(article: dict, section_col: str = \"sections\", max_args_per_sec: int = 2) -> dict:\n",
    "    \"\"\"\n",
    "    Recebe um dicionário de artigo com uma lista de seções e \n",
    "    retorna um dicionário onde as chaves são títulos de seção e os valores são listas \n",
    "    de argumentos faltantes (cada um sendo um dict com 'argument' e 'priority').\n",
    "    Ex: { 'Introdução': [{'argument': '...', 'priority': 1}], ... }\n",
    "    \"\"\"\n",
    "    \n",
    "    missing_by_section = {}\n",
    "    if section_col not in article or not isinstance(article.get(section_col), list):\n",
    "        print(f\"AVISO: Chave '{section_col}' não encontrada no artigo ou não é uma lista.\")\n",
    "        return missing_by_section\n",
    "\n",
    "    for sec in article.get(section_col, []):\n",
    "        if not isinstance(sec, dict) or \"title\" not in sec or \"content\" not in sec:\n",
    "            print(f\"AVISO: Seção ignorada por não ter 'title' ou 'content': {sec}\")\n",
    "            continue\n",
    "        \n",
    "        section_title = sec[\"title\"]\n",
    "        section_content = sec[\"content\"]\n",
    "        \n",
    "        print(f\"Processando seção: {section_title}...\")\n",
    "        args = get_missing_args_for_section(\n",
    "            section_title=section_title,\n",
    "            section_text=section_content,\n",
    "            max_args=max_args_per_sec\n",
    "        )\n",
    "        if args: # Adiciona apenas se a lista de argumentos não estiver vazia\n",
    "            missing_by_section[section_title] = args\n",
    "        else:\n",
    "            print(f\"Nenhum argumento faltante encontrado para a seção: {section_title}\")\n",
    "    return missing_by_section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Função para Sumarizar e Rankear os Principais Argumentos Faltantes do Artigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_missing_args_for_article(\n",
    "    missing_args_by_section: dict, # Dicionário retornado por get_missing_args_for_article\n",
    "    max_summary_items: int = 5,\n",
    "    model_name: str = DEFAULT_MODEL_NAME\n",
    ") -> list[dict]:\n",
    "    \"\"\"\n",
    "    A partir do dicionário {seção: [lista de args faltantes]}, agrupa todos os argumentos,\n",
    "    remove duplicatas ou itens muito semelhantes, e rankeia os `max_summary_items` principais.\n",
    "    Retorna uma lista de dicionários, cada um com 'argument', 'section' (origem), e 'priority'.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not api_key:\n",
    "        return []\n",
    "        \n",
    "    if not missing_args_by_section:\n",
    "        return []\n",
    "\n",
    "    # 1) Flatten: Cria uma lista única de todos os argumentos faltantes com suas seções e prioridades\n",
    "    all_missing_entries = []\n",
    "    for section, args_list in missing_args_by_section.items():\n",
    "        if isinstance(args_list, list): # Garante que args_list é uma lista\n",
    "            for arg_item in args_list:\n",
    "                if isinstance(arg_item, dict) and \"argument\" in arg_item and \"priority\" in arg_item:\n",
    "                    all_missing_entries.append({\n",
    "                        \"section\": section,\n",
    "                        \"argument\": arg_item[\"argument\"],\n",
    "                        \"priority\": arg_item[\"priority\"]\n",
    "                    })\n",
    "                # else: print(f\"DEBUG: Item de argumento ignorado por formato inválido: {arg_item}\")\n",
    "        # else: print(f\"DEBUG: args_list para seção '{section}' não é uma lista: {args_list}\")\n",
    "    \n",
    "    if not all_missing_entries:\n",
    "        print(\"Nenhum argumento válido encontrado após o flatten para sumarização.\")\n",
    "        return []\n",
    "\n",
    "    # 2) Monta o prompt para o LLM, pedindo para consolidar e rankear\n",
    "    prompt_lines = []\n",
    "    for entry in all_missing_entries:\n",
    "        prompt_lines.append(f\"- Da seção '{entry['section']}' (prioridade original {entry['priority']}): \"\n",
    "                            f\"{entry['argument']}\")\n",
    "    \n",
    "    input_arguments_str = \"\\n\".join(prompt_lines)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a senior research assistant and editor.\n",
    "The list below contains suggestions for missing arguments or points identified in different sections of a Wikipedia article.\n",
    "Your task is to consolidate this list by:\n",
    "1. Removing any arguments that are duplicated or semantically very similar to each other, keeping the clearer or more comprehensive version.\n",
    "2. Based on relevance and potential impact for article completeness, select the {max_summary_items} most important missing arguments.\n",
    "3. For each of the {max_summary_items} selected, maintain the information about the source section and original priority.\n",
    "\n",
    "Return your response as a pure JSON list of objects. Each object should have the fields:\n",
    "- \"argument\": The text of the consolidated missing argument.\n",
    "- \"section\": The name of the section where the argument was originally identified.\n",
    "\n",
    "If the input list is empty or contains no valid arguments, return an empty JSON list: `[]`.\n",
    "\n",
    "List of missing arguments for analysis:\n",
    "{input_arguments_str}\n",
    "\"\"\"\n",
    "\n",
    "    try:\n",
    "        model_client = genai.GenerativeModel(model_name)\n",
    "        generation_config = genai.types.GenerationConfig(temperature=DEFAULT_TEMPERATURE)\n",
    "        \n",
    "        # print(f\"DEBUG: Enviando prompt para sumarização:\\n{prompt[:500]}...\")\n",
    "        response = model_client.generate_content(prompt, generation_config=generation_config)\n",
    "        \n",
    "        # print(f\"DEBUG: Resposta crua da API para sumarização:\\n{response.text if hasattr(response, 'text') else response}\")\n",
    "        \n",
    "        response_content = \"\"\n",
    "        if response and hasattr(response, 'text') and response.text:\n",
    "            response_content = response.text\n",
    "        elif response and response.parts:\n",
    "             response_content = \"\".join([part.text for part in response.parts if hasattr(part, 'text')])\n",
    "\n",
    "        if response_content:\n",
    "            parsed_response = _parse_llm_json_response(response_content)\n",
    "            if isinstance(parsed_response, list):\n",
    "                return parsed_response\n",
    "            elif isinstance(parsed_response, dict) and parsed_response:\n",
    "                return [parsed_response]\n",
    "            else:\n",
    "                # print(f\"WARN: Resposta JSON da sumarização não era uma lista. Resposta: {parsed_response}\")\n",
    "                return []\n",
    "        else:\n",
    "            # print(\"WARN: Resposta inesperada, vazia ou sem texto processável do modelo para sumarização.\")\n",
    "            return []\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao chamar a API Gemini para sumarização: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Exemplo de Artigo e Execução do Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'gemini-1.5-flash-latest' verificado com sucesso.\n",
      "\n",
      "--- Iniciando análise de argumentos faltantes no artigo ---\n",
      "Processando seção: Introduction to AI...\n",
      "Processando seção: Brief History of AI...\n",
      "Processando seção: Current Main AI Techniques...\n",
      "Processando seção: Examples of AI Applications...\n",
      "\n",
      "--- Argumentos faltantes identificados por seção ---\n",
      "\n",
      "Seção: Introduction to AI\n",
      "  - Prioridade 1: The ethical implications of AI development and deployment are largely absent.  The excerpt focuses solely on the technical capabilities of AI, neglecting crucial discussions around bias in algorithms, job displacement due to automation, the potential for misuse in surveillance or autonomous weapons systems, and the broader societal impact of increasingly intelligent machines.  A balanced introduction to AI should acknowledge these concerns.\n",
      "  - Prioridade 2: Different approaches and paradigms within AI are not mentioned. The excerpt presents a very general definition.  A richer introduction would briefly touch upon the distinctions between symbolic AI, connectionist AI (neural networks), evolutionary AI, and other methodologies, highlighting their strengths and weaknesses and the ongoing debates within the field.\n",
      "\n",
      "Seção: Brief History of AI\n",
      "  - Prioridade 1: The ethical implications and societal impact of AI development were largely absent from this historical overview.  The excerpt focuses on technical milestones but neglects to discuss the concurrent emergence of concerns about job displacement, algorithmic bias, and the potential misuse of AI technologies.  A balanced history should acknowledge these parallel narratives.\n",
      "  - Prioridade 2: The excerpt primarily highlights the Western perspective on AI's history.  Contributions from researchers and developments in other parts of the world, which may have been significant but less documented in Western literature, are not mentioned.  A more comprehensive history would acknowledge and incorporate these diverse influences.\n",
      "\n",
      "Seção: Current Main AI Techniques\n",
      "  - Prioridade 1: The limitations and potential biases inherent in current dominant AI techniques are not discussed.  While the excerpt highlights the success of CNNs and Transformers, it omits crucial counterarguments regarding their susceptibility to biases present in training data, their computational cost and energy consumption, their lack of explainability ('black box' nature), and their potential for misuse or unintended consequences.  A balanced discussion should acknowledge these limitations alongside their successes.\n",
      "  - Prioridade 2: Alternative AI approaches beyond deep learning are largely absent. The excerpt focuses almost exclusively on deep learning methods.  A more comprehensive overview would include mention of other significant AI techniques, such as symbolic AI, evolutionary algorithms, or reinforcement learning, and briefly compare their strengths and weaknesses relative to deep learning in various applications. This would provide a more nuanced and complete picture of the current AI landscape.\n",
      "\n",
      "Seção: Examples of AI Applications\n",
      "  - Prioridade 1: The ethical implications and societal impact of AI applications are largely absent.  The excerpt focuses solely on the technical applications, neglecting crucial discussions around issues like algorithmic bias in medical diagnosis or personalized recommendations, job displacement due to automation in logistics and manufacturing, and the potential for misuse in financial markets (e.g., exacerbating existing inequalities).\n",
      "  - Prioridade 2: The limitations and challenges of current AI technologies are understated. While the excerpt showcases successful applications, it omits crucial counterpoints such as the limitations of current AI in handling complex, nuanced situations (e.g., the limitations of autonomous vehicles in unpredictable environments or the challenges of interpreting medical images with high accuracy), the need for large datasets for training, and the ongoing debate about the explainability and transparency of AI decision-making processes.\n",
      "\n",
      "--- Sumarizando os principais argumentos faltantes do artigo ---\n",
      "\n",
      "Principais argumentos faltantes no artigo (sumarizado):\n",
      "  - Seção 'Introduction to AI': The ethical implications of AI development and deployment are largely absent. This includes bias in algorithms, job displacement due to automation, potential misuse in surveillance or autonomous weapons, and broader societal impact. A balanced discussion should acknowledge these concerns. (Prioridade Original: N/A)\n",
      "  - Seção 'Introduction to AI': Different approaches and paradigms within AI are not mentioned.  The article should briefly discuss symbolic AI, connectionist AI (neural networks), evolutionary AI, and other methodologies, highlighting their strengths and weaknesses and ongoing debates. (Prioridade Original: N/A)\n",
      "  - Seção 'Brief History of AI': The ethical implications and societal impact of AI development are missing from the historical overview.  The excerpt focuses on technical milestones but neglects concerns about job displacement, algorithmic bias, and potential misuse of AI technologies. (Prioridade Original: N/A)\n",
      "  - Seção 'Current Main AI Techniques': The limitations and potential biases inherent in current dominant AI techniques are not discussed.  The article should address biases in training data, computational cost and energy consumption, lack of explainability, and potential for misuse or unintended consequences. (Prioridade Original: N/A)\n",
      "  - Seção 'Examples of AI Applications': The ethical implications and societal impact of AI applications are largely absent. The article should discuss algorithmic bias in various applications, job displacement due to automation, and the potential for misuse in different sectors (e.g., finance). (Prioridade Original: N/A)\n"
     ]
    }
   ],
   "source": [
    "# Artigo fictício sobre IA com omissões deliberadas para teste\n",
    "mock_article = {\n",
    "    \"id\": 101010,\n",
    "    \"title\": \"Artificial Intelligence: Fundamentals and Applications\",\n",
    "    \"sections\": [\n",
    "        {\n",
    "            \"title\": \"Introduction to AI\",\n",
    "            \"content\": (\n",
    "                \"Artificial Intelligence (AI) is a branch of computer science \"\n",
    "                \"dedicated to creating systems capable of performing tasks that normally \"\n",
    "                \"would require human intelligence. This includes, but is not limited to, natural language \"\n",
    "                \"processing, complex pattern recognition, and autonomous decision-making.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Brief History of AI\",\n",
    "            \"content\": (\n",
    "                \"The formal concept of AI can be traced back to Alan Turing's pioneering work in the 1950s, \"\n",
    "                \"particularly with the proposal of the Turing Test as a way to evaluate machine intelligence. \"\n",
    "                \"Later, between the 1960s and 1970s, the first expert systems emerged, \"\n",
    "                \"which used knowledge bases and rules encoded by experts to solve \"\n",
    "                \"problems in specific domains. After a period of reduced investment and progress, known as the 'AI winter', \"\n",
    "                \"the field experienced a significant resurgence from the 1990s, driven mainly \"\n",
    "                \"by significant advances in computational capacity and the availability of large volumes of data.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Current Main AI Techniques\",\n",
    "            \"content\": (\n",
    "                \"Currently, the AI field is heavily influenced by machine learning algorithms, \"\n",
    "                \"with emphasis on deep learning. Convolutional Neural Networks (CNNs) are \"\n",
    "                \"widely used in computer vision tasks, such as image and video recognition, \"\n",
    "                \"while architectures like Recurrent Neural Networks (RNNs) and, more prominently, Transformers \"\n",
    "                \"dominate natural language processing applications, such as machine translation and text generation.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"title\": \"Examples of AI Applications\",\n",
    "            \"content\": (\n",
    "                \"The commercial, industrial, and scientific applications of Artificial Intelligence are vast and include:\\n\"\n",
    "                \"- Computer-assisted medical diagnosis, medical image analysis, and drug discovery.\\n\"\n",
    "                \"- Personalized recommendation systems in e-commerce platforms, streaming, and social networks.\\n\"\n",
    "                \"- Development of autonomous vehicles, logistics route optimization, and intelligent traffic management.\\n\"\n",
    "                \"- Financial data analysis for fraud detection, market trend prediction, and algorithmic trading.\"\n",
    "            )\n",
    "        }\n",
    "        # Intentional note: This article deliberately omits crucial discussions about:\n",
    "        # - AI Ethics (e.g., algorithmic bias, privacy, responsibility)\n",
    "        # - Social and economic impact of AI (e.g., job market, inequality)\n",
    "        # - AI model security and robustness (e.g., adversarial attacks, explainability)\n",
    "        # - AI alignment issues (ensuring advanced AIs act according to human values)\n",
    "        # - Current AI limitations and future research challenges.\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Execução do pipeline\n",
    "if api_key:\n",
    "    # Verifica se o modelo padrão é válido antes de prosseguir\n",
    "    model_is_valid = False\n",
    "    try:\n",
    "        genai.get_model(f\"models/{DEFAULT_MODEL_NAME}\") # A API espera o prefixo 'models/'\n",
    "        model_is_valid = True\n",
    "        print(f\"Modelo '{DEFAULT_MODEL_NAME}' verificado com sucesso.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERRO ao verificar o modelo '{DEFAULT_MODEL_NAME}': {e}\")\n",
    "        print(\"Verifique se o nome do modelo está correto e se você tem acesso a ele.\")\n",
    "\n",
    "    if model_is_valid:\n",
    "        print(\"\\n--- Iniciando análise de argumentos faltantes no artigo ---\")\n",
    "        missing_args_all_sections = get_missing_args_for_article(mock_article, max_args_per_sec=2)\n",
    "        \n",
    "        print(\"\\n--- Argumentos faltantes identificados por seção ---\")\n",
    "        if missing_args_all_sections:\n",
    "            for section, args in missing_args_all_sections.items():\n",
    "                print(f\"\\nSeção: {section}\")\n",
    "                if args: # Verifica se a lista de args não é None ou vazia\n",
    "                    for arg_item in args:\n",
    "                        print(f\"  - Prioridade {arg_item.get('priority', 'N/A')}: {arg_item.get('argument', 'Argumento não especificado')}\")\n",
    "                else:\n",
    "                    print(\"  Nenhum argumento faltante retornado para esta seção.\")\n",
    "        else:\n",
    "            print(\"Nenhum argumento faltante identificado em nenhuma seção.\")\n",
    "\n",
    "        print(\"\\n--- Sumarizando os principais argumentos faltantes do artigo ---\")\n",
    "        summary_top_missing = summarize_missing_args_for_article(missing_args_all_sections, max_summary_items=5)\n",
    "\n",
    "        if summary_top_missing:\n",
    "            print(\"\\nPrincipais argumentos faltantes no artigo (sumarizado):\")\n",
    "            for item in summary_top_missing:\n",
    "                print(f\"  - Seção '{item.get('section', 'N/A')}': {item.get('argument', 'N/A')} (Prioridade Original: {item.get('priority', 'N/A')})\")\n",
    "        else:\n",
    "            print(\"Nenhum argumento faltante para sumarizar ou a sumarização falhou.\")\n",
    "    else:\n",
    "        print(\"\\nExecução do pipeline principal pulada devido a erro na verificação do modelo.\")\n",
    "else:\n",
    "    print(\"\\nExecução do pipeline principal pulada. Verifique a configuração da GENAI_API_KEY.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
