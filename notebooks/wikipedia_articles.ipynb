{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 1: Imports e configurações gerais\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "WIKI_API = \"https://en.wikipedia.org/w/api.php\"\n",
    "PAGEVIEWS_PER_ARTICLE = \"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article\"\n",
    "PROJECT = \"en.wikipedia\"\n",
    "ACCESS = \"all-access\"\n",
    "AGENT = \"user\"\n",
    "GRANULARITY = \"daily\"\n",
    "\n",
    "TOPICS = [\n",
    "    \"Artificial Intelligence\", \"AI\", \"Business\",\n",
    "    \"Finance\", \"Machine Learning\", \"Neural Networks\", \"Tech\"\n",
    "]\n",
    "MAX_SEARCH_PER_TOPIC = 100   # títulos buscados por tópico\n",
    "MAX_CANDIDATES = 500         # quantos candidatos de views medir\n",
    "TOP_K = 50                   # quantos artigos finais exibir\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 2: Obter títulos relevantes por tópico (síncrono)\n",
    "def search_titles(topic, limit=MAX_SEARCH_PER_TOPIC):\n",
    "    params = {\n",
    "        \"action\":  \"query\",\n",
    "        \"format\":  \"json\",\n",
    "        \"list\":    \"search\",\n",
    "        \"srsearch\": topic,\n",
    "        \"srlimit\": limit,\n",
    "        \"srsort\":  \"relevance\",\n",
    "        \"srprop\":  \"\"\n",
    "    }\n",
    "    r = requests.get(WIKI_API, params=params)\n",
    "    return [i[\"title\"] for i in r.json().get(\"query\", {}).get(\"search\", [])]\n",
    "\n",
    "def get_relevant_titles(topics):\n",
    "    titles = []\n",
    "    for t in topics:\n",
    "        for title in search_titles(t):\n",
    "            if title not in titles:\n",
    "                titles.append(title)\n",
    "            if len(titles) >= MAX_CANDIDATES:\n",
    "                return titles\n",
    "    return titles\n",
    "\n",
    "relevant_titles = get_relevant_titles(TOPICS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 3: Buscar contagem de views por artigo (assíncrono)\n",
    "async def fetch_views(session, title, date_dt):\n",
    "    date_str = date_dt.strftime(\"%Y%m%d\")\n",
    "    url = f\"{PAGEVIEWS_PER_ARTICLE}/{PROJECT}/{ACCESS}/{AGENT}/{title.replace(' ', '_')}/{GRANULARITY}/{date_str}/{date_str}\"\n",
    "    async with session.get(url) as resp:\n",
    "        if resp.status != 200:\n",
    "            return title, 0\n",
    "        data = await resp.json()\n",
    "    views = data.get(\"items\", [{}])[0].get(\"views\", 0)\n",
    "    return title, views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 4: Orquestrar tudo, calcular score e ordenar\n",
    "async def main(date_str: str = None):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        trending = await fetch_trending(session, date_str)\n",
    "        tasks = [fetch_page(session, t) for t in trending]\n",
    "        raw = await asyncio.gather(*tasks)\n",
    "\n",
    "    articles = [a for a in raw if a]\n",
    "    topic_keys = [t.lower() for t in TOPICS]\n",
    "    for art in articles:\n",
    "        txt = \" \".join([art[\"title\"], art[\"summary\"], art[\"content\"]]).lower()\n",
    "        art[\"score\"] = sum(kw in txt for kw in topic_keys)\n",
    "\n",
    "    # ordena primeiro por views (trending) e depois por score de tópicos\n",
    "    articles.sort(key=lambda x: (x[\"score\"], x[\"views\"]), reverse=True)\n",
    "    top = articles[:TOP_K]\n",
    "    return pd.DataFrame(top, columns=[\n",
    "        \"id\", \"title\", \"url\", \"summary\", \"content\", \"image\", \"views\", \"score\"\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 4: Buscar detalhes da página (assíncrono)\n",
    "async def fetch_page(session, title, views):\n",
    "    params = {\n",
    "        \"action\":      \"query\",\n",
    "        \"format\":      \"json\",\n",
    "        \"prop\":        \"extracts|info|pageimages\",\n",
    "        \"explaintext\": 1,\n",
    "        \"redirects\":   1,\n",
    "        \"inprop\":      \"url\",\n",
    "        \"piprop\":      \"original\",\n",
    "        \"titles\":      title\n",
    "    }\n",
    "    async with session.get(WIKI_API, params=params) as resp:\n",
    "        js = await resp.json()\n",
    "    page = next(iter(js.get(\"query\", {}).get(\"pages\", {}).values()), {})\n",
    "    pid = page.get(\"pageid\")\n",
    "    if not pid or \"missing\" in page:\n",
    "        return None\n",
    "    text = page.get(\"extract\", \"\")\n",
    "    summary = text.split(\"\\n\\n\")[0] if text else \"\"\n",
    "    return {\n",
    "        \"id\":      pid,\n",
    "        \"title\":   page.get(\"title\", \"\"),\n",
    "        \"url\":     page.get(\"fullurl\", \"\"),\n",
    "        \"summary\": summary,\n",
    "        \"content\": text,\n",
    "        \"image\":   page.get(\"original\", {}).get(\"source\"),\n",
    "        \"views\":   views\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bloco 5: Orquestrar consultas, filtrar e montar DataFrame\n",
    "async def main(date_str: str = None):\n",
    "    # define data alvo\n",
    "    if date_str:\n",
    "        date_dt = datetime.strptime(date_str, \"%Y/%m/%d\").date()\n",
    "    else:\n",
    "        date_dt = datetime.utcnow().date() - timedelta(days=1)\n",
    "\n",
    "    # busca views\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        vs_tasks = [fetch_views(session, t, date_dt) for t in relevant_titles]\n",
    "        vs_results = await asyncio.gather(*vs_tasks)\n",
    "\n",
    "    # filtra só quem teve views > 0 e ordena\n",
    "    vs_filtered = [(t, v) for t, v in vs_results if v > 0]\n",
    "    vs_filtered.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_titles = [t for t, _ in vs_filtered[:TOP_K]]\n",
    "\n",
    "    # busca detalhes\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        pg_tasks = [fetch_page(session, t, dict(vs_results)[t]) for t in top_titles]\n",
    "        pages = await asyncio.gather(*pg_tasks)\n",
    "\n",
    "    # monta DataFrame\n",
    "    articles = [p for p in pages if p]\n",
    "    # opcional: calcular score de tópicos secundário\n",
    "    tk = [kw.lower() for kw in TOPICS]\n",
    "    for art in articles:\n",
    "        txt = \" \".join([art[\"title\"], art[\"summary\"], art[\"content\"]]).lower()\n",
    "        art[\"score\"] = sum(kw in txt for kw in tk)\n",
    "\n",
    "    df = pd.DataFrame(articles)\n",
    "    return df.sort_values([\"views\",\"score\"], ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "      <th>image</th>\n",
       "      <th>views</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>72417803</td>\n",
       "      <td>ChatGPT</td>\n",
       "      <td>https://en.wikipedia.org/wiki/ChatGPT</td>\n",
       "      <td>ChatGPT is a generative artificial intelligenc...</td>\n",
       "      <td>ChatGPT is a generative artificial intelligenc...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>77235</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32058867</td>\n",
       "      <td>WhatsApp</td>\n",
       "      <td>https://en.wikipedia.org/wiki/WhatsApp</td>\n",
       "      <td>WhatsApp (officially WhatsApp Messenger) is an...</td>\n",
       "      <td>WhatsApp (officially WhatsApp Messenger) is an...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>16707</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1164</td>\n",
       "      <td>Artificial intelligence</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Artificial_intel...</td>\n",
       "      <td>Artificial intelligence (AI) refers to the cap...</td>\n",
       "      <td>Artificial intelligence (AI) refers to the cap...</td>\n",
       "      <td>None</td>\n",
       "      <td>9883</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48795986</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>https://en.wikipedia.org/wiki/OpenAI</td>\n",
       "      <td>OpenAI, Inc. is an American artificial intelli...</td>\n",
       "      <td>OpenAI, Inc. is an American artificial intelli...</td>\n",
       "      <td>None</td>\n",
       "      <td>7481</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6886</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Chicago</td>\n",
       "      <td>Chicago is the most populous city in the U.S. ...</td>\n",
       "      <td>Chicago is the most populous city in the U.S. ...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>7167</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>79371410</td>\n",
       "      <td>Vibe coding</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Vibe_coding</td>\n",
       "      <td>Vibe coding (or vibecoding) is an approach to ...</td>\n",
       "      <td>Vibe coding (or vibecoding) is an approach to ...</td>\n",
       "      <td>None</td>\n",
       "      <td>5618</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75223933</td>\n",
       "      <td>Grok (chatbot)</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Grok_(chatbot)</td>\n",
       "      <td>Grok is a generative artificial intelligence c...</td>\n",
       "      <td>Grok is a generative artificial intelligence c...</td>\n",
       "      <td>https://upload.wikimedia.org/wikipedia/commons...</td>\n",
       "      <td>5422</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78452842</td>\n",
       "      <td>DeepSeek</td>\n",
       "      <td>https://en.wikipedia.org/wiki/DeepSeek</td>\n",
       "      <td>Hangzhou DeepSeek Artificial Intelligence Basi...</td>\n",
       "      <td>Hangzhou DeepSeek Artificial Intelligence Basi...</td>\n",
       "      <td>None</td>\n",
       "      <td>5138</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73248112</td>\n",
       "      <td>Large language model</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Large_language_m...</td>\n",
       "      <td>A large language model (LLM) is a type of mach...</td>\n",
       "      <td>A large language model (LLM) is a type of mach...</td>\n",
       "      <td>None</td>\n",
       "      <td>4266</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>75743156</td>\n",
       "      <td>Perplexity AI</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Perplexity_AI</td>\n",
       "      <td>Perplexity AI, or simply Perplexity, is an Ame...</td>\n",
       "      <td>Perplexity AI, or simply Perplexity, is an Ame...</td>\n",
       "      <td>None</td>\n",
       "      <td>3824</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                    title  \\\n",
       "0  72417803                  ChatGPT   \n",
       "1  32058867                 WhatsApp   \n",
       "2      1164  Artificial intelligence   \n",
       "3  48795986                   OpenAI   \n",
       "4      6886                  Chicago   \n",
       "5  79371410              Vibe coding   \n",
       "6  75223933           Grok (chatbot)   \n",
       "7  78452842                 DeepSeek   \n",
       "8  73248112     Large language model   \n",
       "9  75743156            Perplexity AI   \n",
       "\n",
       "                                                 url  \\\n",
       "0              https://en.wikipedia.org/wiki/ChatGPT   \n",
       "1             https://en.wikipedia.org/wiki/WhatsApp   \n",
       "2  https://en.wikipedia.org/wiki/Artificial_intel...   \n",
       "3               https://en.wikipedia.org/wiki/OpenAI   \n",
       "4              https://en.wikipedia.org/wiki/Chicago   \n",
       "5          https://en.wikipedia.org/wiki/Vibe_coding   \n",
       "6       https://en.wikipedia.org/wiki/Grok_(chatbot)   \n",
       "7             https://en.wikipedia.org/wiki/DeepSeek   \n",
       "8  https://en.wikipedia.org/wiki/Large_language_m...   \n",
       "9        https://en.wikipedia.org/wiki/Perplexity_AI   \n",
       "\n",
       "                                             summary  \\\n",
       "0  ChatGPT is a generative artificial intelligenc...   \n",
       "1  WhatsApp (officially WhatsApp Messenger) is an...   \n",
       "2  Artificial intelligence (AI) refers to the cap...   \n",
       "3  OpenAI, Inc. is an American artificial intelli...   \n",
       "4  Chicago is the most populous city in the U.S. ...   \n",
       "5  Vibe coding (or vibecoding) is an approach to ...   \n",
       "6  Grok is a generative artificial intelligence c...   \n",
       "7  Hangzhou DeepSeek Artificial Intelligence Basi...   \n",
       "8  A large language model (LLM) is a type of mach...   \n",
       "9  Perplexity AI, or simply Perplexity, is an Ame...   \n",
       "\n",
       "                                             content  \\\n",
       "0  ChatGPT is a generative artificial intelligenc...   \n",
       "1  WhatsApp (officially WhatsApp Messenger) is an...   \n",
       "2  Artificial intelligence (AI) refers to the cap...   \n",
       "3  OpenAI, Inc. is an American artificial intelli...   \n",
       "4  Chicago is the most populous city in the U.S. ...   \n",
       "5  Vibe coding (or vibecoding) is an approach to ...   \n",
       "6  Grok is a generative artificial intelligence c...   \n",
       "7  Hangzhou DeepSeek Artificial Intelligence Basi...   \n",
       "8  A large language model (LLM) is a type of mach...   \n",
       "9  Perplexity AI, or simply Perplexity, is an Ame...   \n",
       "\n",
       "                                               image  views  score  \n",
       "0  https://upload.wikimedia.org/wikipedia/commons...  77235      6  \n",
       "1  https://upload.wikimedia.org/wikipedia/commons...  16707      5  \n",
       "2                                               None   9883      7  \n",
       "3                                               None   7481      6  \n",
       "4  https://upload.wikimedia.org/wikipedia/commons...   7167      4  \n",
       "5                                               None   5618      4  \n",
       "6  https://upload.wikimedia.org/wikipedia/commons...   5422      5  \n",
       "7                                               None   5138      4  \n",
       "8                                               None   4266      5  \n",
       "9                                               None   3824      4  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bloco 6: Executar no Jupyter e exibir\n",
    "df = await main()               # padrão: ontem\n",
    "# df = await main(\"2025/05/10\") # data específica\n",
    "df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
